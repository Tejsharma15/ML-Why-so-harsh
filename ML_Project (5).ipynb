{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDNeYR4WLYIr"
      },
      "source": [
        "## **Installing and Importing Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQ1gBqQ4MhPf",
        "outputId": "af30e014-8f9f-4542-9d4b-b9fc936f9e14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting stop-words\n",
            "  Downloading stop-words-2018.7.23.tar.gz (31 kB)\n",
            "Building wheels for collected packages: stop-words\n",
            "  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stop-words: filename=stop_words-2018.7.23-py3-none-any.whl size=32910 sha256=0de4c7646e4d7ae4234e614dd342de70a3438f0058fdea509101a94d5c1fd30d\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/86/b2/277b10b1ce9f73ce15059bf6975d4547cc4ec3feeb651978e9\n",
            "Successfully built stop-words\n",
            "Installing collected packages: stop-words\n",
            "Successfully installed stop-words-2018.7.23\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-multilearn\n",
            "  Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n",
            "\u001b[K     |████████████████████████████████| 89 kB 8.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting anyascii\n",
            "  Downloading anyascii-0.3.1-py3-none-any.whl (287 kB)\n",
            "\u001b[K     |████████████████████████████████| 287 kB 30.4 MB/s \n",
            "\u001b[?25hCollecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 71.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.1 contractions-0.1.73 pyahocorasick-1.4.4 textsearch-0.0.24\n"
          ]
        }
      ],
      "source": [
        "!pip install stop-words\n",
        "!pip install nltk\n",
        "!pip install scikit-multilearn\n",
        "!pip install contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDmR682Kqa1a",
        "outputId": "8995684d-513f-4cd3-f09e-a250a53947f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd;\n",
        "import numpy as np;\n",
        "import matplotlib.pyplot as plt;\n",
        "import seaborn as sns;\n",
        "import nltk\n",
        "import copy\n",
        "import re\n",
        "import contractions\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from scipy.sparse import csr_matrix, hstack\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
        "from skmultilearn.problem_transform import BinaryRelevance\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "# from sklearn.model_selection import cv\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.pipeline import Pipeline,make_union\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk import word_tokenize, pos_tag;\n",
        "from nltk.corpus import stopwords, wordnet;\n",
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "nltk.download('omw-1.4')\n",
        "#from stop_words import get_stop_words\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vw0T-dWHi_pj"
      },
      "outputs": [],
      "source": [
        " from google.colab import drive\n",
        " drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hu-fBmdeLidD"
      },
      "source": [
        "## **Initial data analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zxHnvlAqOa8"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/ML_Project/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/ML_Project/test.csv')\n",
        "#train.head()\n",
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fx6wMwO6ZAcs"
      },
      "outputs": [],
      "source": [
        "targets = list(train.columns[2:])\n",
        "df_targets = train[targets].copy()\n",
        "\n",
        "# How many rows are toxic? \n",
        "toxic_rows = df_targets.sum(axis=1)\n",
        "toxic_rows = (toxic_rows > 0)\n",
        "\n",
        "# Create overall any_label feature\n",
        "targets.append('any_label')\n",
        "df_targets['any_label'] = toxic_rows\n",
        "\n",
        "count_dic = {}\n",
        "for comment_type in targets:\n",
        "    counts = list()\n",
        "    others = list(targets)\n",
        "    df_selection = df_targets[(df_targets[comment_type]==1)]\n",
        "    others.remove(comment_type)\n",
        "    counts.append(('total', len(df_selection)))\n",
        "    for other in others:\n",
        "        counts.append((other, df_selection[other].sum()))\n",
        "    count_dic[comment_type] = counts\n",
        "\n",
        "\n",
        "del(df_selection)\n",
        "\n",
        "def heatmap(df, title):\n",
        "    plt.figure('heatmap', figsize=[10,10])\n",
        "    plt.title(title)\n",
        "    df_corr = df.corr()\n",
        "    #df_corr = np.triu(df_corr, k=1)\n",
        "    sns.heatmap(df_corr, vmax=0.6, square=True, annot=True, cmap='YlOrRd')\n",
        "    plt.yticks(rotation = 45)\n",
        "    plt.xticks(rotation = 45)\n",
        "    plt.show()\n",
        "\n",
        "heatmap(df_targets, 'Comment Type Heatmap')\n",
        "\n",
        "\n",
        "print('Training Data Comment Breakdown')\n",
        "print('=====\\n')\n",
        "\n",
        "print('%d out of %d comments, or %.2f%%, are classified as toxic.' % \n",
        "     (np.sum(toxic_rows), len(train), (np.sum(toxic_rows)/len(train))*100))\n",
        "\n",
        "totals = []\n",
        "for key, value in count_dic.items():\n",
        "    totals.append(value[0][1])\n",
        "    print('\\n%d %s comments. (%.2f%% of all data.)' % (value[0][1], key, (value[0][1]/len(train))*100))\n",
        "    for cnt in value[1:]:\n",
        "        print('- %d or %.2f%% were also %s.' % (cnt[1], (cnt[1]/value[0][1])*100, cnt[0]))\n",
        "    \n",
        "\n",
        "plt.figure('Comment Type Counts', figsize=[8,6])\n",
        "plt.title('Comment Type Counts')\n",
        "sns.barplot(x=list(count_dic.keys()), y=totals)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KYPFzXEicxc"
      },
      "outputs": [],
      "source": [
        "def feature_engineering(dataframe, sparse=0): \n",
        "    \n",
        "    # Comment length\n",
        "    dataframe['length'] = dataframe.text.apply(lambda x: len(x))\n",
        "    \n",
        "\n",
        "    # Capitalization percentage\n",
        "    def pct_caps(s):\n",
        "      Caps=0\n",
        "      total = 0\n",
        "      for c in s:\n",
        "        if c.isupper() == 1:\n",
        "          Caps+=1\n",
        "      for c in s:\n",
        "        if c.isalpha() == 1:\n",
        "          total+=1\n",
        "      return Caps/(total+1)\n",
        "    dataframe['caps'] = dataframe.text.apply(lambda x: pct_caps(x))\n",
        "\n",
        "    # Mean Word length \n",
        "    def word_length(s):\n",
        "        s = s.split(' ')\n",
        "        return np.mean([len(w) for w in s if w.isalpha()])\n",
        "    dataframe['word_length'] = dataframe.text.apply(lambda x: word_length(x))\n",
        "\n",
        "    # # Average number of exclamation points \n",
        "    # dataframe['exclamation'] = dataframe.text.apply(lambda s: len([c for c in s if c == '!']))\n",
        "\n",
        "    # # Average number of question marks \n",
        "    # dataframe['question'] = dataframe.text.apply(lambda s: len([c for c in s if c == '?']))\n",
        "    \n",
        "    # Normalize\n",
        "    for label in ['length', 'caps', 'word_length']:\n",
        "        minimum = dataframe[label].min()\n",
        "        diff = dataframe[label].max() - minimum\n",
        "        dataframe[label] = dataframe[label].apply(lambda x: (x-minimum) / (diff))\n",
        "    return dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FqYxqrH6NXl"
      },
      "outputs": [],
      "source": [
        "output = train.iloc[:, 2:8]   #Splitting the data into input and output data. \n",
        "input = train.iloc[:, 0:2]\n",
        "testInput = test.iloc[:, 0:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfl60f5tidz4"
      },
      "outputs": [],
      "source": [
        "train = feature_engineering(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GihiVAC85D78"
      },
      "outputs": [],
      "source": [
        "test = feature_engineering(testInput)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xea3R1K9hMJ2"
      },
      "outputs": [],
      "source": [
        "test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f20INjue64fX"
      },
      "source": [
        "##**Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qErGwnQ3ObuR"
      },
      "outputs": [],
      "source": [
        "# def summarizer(text): #Takes text as a comment and finds the summary of the text and returns the summary as tokens.\n",
        "#   def tokenize(text):\n",
        "#     return word_tokenize(text)   #To tokenize the words.\n",
        "#   def removeURL(text):\n",
        "#     return re.sub(r\"http\\S+\", \"\", text)\n",
        "#   def toLower(text):            #To convert all words into lowercase\n",
        "#     return [text.lower() for text in text]\n",
        "#   def removePunc(text):          #To remove punctuation marks from the text.\n",
        "#     w = []\n",
        "#     for word in text:\n",
        "#       if(word.isalnum()):\n",
        "#         w.append(word)\n",
        "#     return w\n",
        "#   def modify(text):  #Remove words of length< 2\n",
        "#     w = []\n",
        "#     for word in text:\n",
        "#       if(len(word) > 2):\n",
        "#         w.append(word)\n",
        "#     return w\n",
        "#   def stopwordRem(text):         #To remove stopwords from the text.\n",
        "#     stopword = stopwords.words('english')\n",
        "#     text = list(filter(lambda word: word not in stopword, text))\n",
        "#     return text\n",
        "#   def remove_numbers(text):\n",
        "#       pattern = r'[^a-zA-z.,!?/:;\\\"\\'\\s]' \n",
        "#       return re.sub(pattern, '', text)\n",
        "#   def remove_spaces&singlechar(text):\n",
        "#       sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "#       sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "#       return sentence\n",
        "#   def lemmatize(text):          #To lemmatize the text using the parts of speech tag.\n",
        "#     def PartOfSpeechTag(text):\n",
        "#       tag = pos_tag([text])\n",
        "#       pos = tag[0][1]\n",
        "#       tag_to_map = {\"JJ\": wordnet.ADJ,\n",
        "#                   \"NN\": wordnet.NOUN,\n",
        "#                   \"VBG\": wordnet.VERB,\n",
        "#                   \"RB\": wordnet.ADV}\n",
        "#       return tag_to_map.get(pos, wordnet.NOUN)\n",
        "#     lemma = WordNetLemmatizer()\n",
        "#     lemmatized_text = \"\"\n",
        "#     for w in text:\n",
        "#       pos = PartOfSpeechTag(w)\n",
        "#       lemmatized_text += lemma.lemmatize(w, pos) + \" \"\n",
        "#     return lemmatized_text\n",
        "    \n",
        "#   text = removeURL(text)\n",
        "#   # text = remove_numbers(text)\n",
        "#   text = tokenize(text)\n",
        "#   # text = modify(text)\n",
        "#   text = toLower(text)\n",
        "#   text = removePunc(text)\n",
        "#   # text = stopwordRem(text)\n",
        "#   # text = lemmatize(text)\n",
        "#   return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOyLChY6Uf2f"
      },
      "outputs": [],
      "source": [
        "# preprocessed_comments = []  #Calling the summarizer function and passing the text into the summarizer Written by: Tejas Sharma\n",
        "# for i in range(len(X_train)):\n",
        "#   if(i%1000 == 1):\n",
        "#     print(i)\n",
        "#   text = X_train._get_value(i, 'text', takeable=False)\n",
        "#   preprocessed_comments.append(summarizer(text))\n",
        "# preprocessed_comments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPSxV2VKUgko"
      },
      "outputs": [],
      "source": [
        "# preprocessed_test_comments = []\n",
        "# for i in range(len(X_test)):\n",
        "#   if((i%1000) == 1):\n",
        "#     print(i)\n",
        "#   text = X_test._get_value(i+71451, 'text', takeable=False)\n",
        "#   preprocessed_test_comments.append(summarizer(text))\n",
        "# preprocessed_test_comments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-O7sWu3jAm3X"
      },
      "outputs": [],
      "source": [
        "# preprocessed_comments = []  #Calling the summarizer function and passing the text into the summarizer for training comments\n",
        "# input['clean_text'] = input.text.apply(lambda text: summarizer(text))\n",
        "# input.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NdPcwu1Fi_o"
      },
      "outputs": [],
      "source": [
        "# testInput['clean_text'] = testInput.text.apply(lambda x: summarizer(x))\n",
        "# testInput.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sl4_m--MW_4G"
      },
      "outputs": [],
      "source": [
        "# input.to_csv(\"preprocessed_Data.csv\")\n",
        "# testInput.to_csv(\"preprocessed_VData.csv\")\n",
        "# !cp preprocessed_Data.csv /content/drive/MyDrive/ML_Project\n",
        "# !cp preprocessed_VData.csv /content/drive/MyDrive/ML_Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UX2AbyuU7nTP"
      },
      "outputs": [],
      "source": [
        "# preprocessed_Data = pd.DataFrame(preprocessed_comments)\n",
        "# preprocessed_Data.to_csv(\"preprocessed_Data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oPFWpAkXSj7"
      },
      "outputs": [],
      "source": [
        "inputTest = pd.read_csv(\"/content/drive/MyDrive/ML_Project/preprocessed_VData.csv\")\n",
        "inputTest[\"clean_text\"].fillna(\"no text\", inplace = True)\n",
        "test_Comments=[]\n",
        "for i in range(len(inputTest)):\n",
        "  test_Comments.append(inputTest.iloc[i][\"clean_text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m053XtZuYyEE"
      },
      "outputs": [],
      "source": [
        "input = pd.read_csv(\"/content/drive/MyDrive/ML_Project/preprocessed_Data.csv\")\n",
        "input[\"clean_text\"].fillna(\"no text\", inplace = True)\n",
        "Comments=[]\n",
        "for i in range(len(input)):\n",
        "  Comments.append(input.iloc[i][\"clean_text\"])\n",
        "input[\"clean_text\"].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCVkDkLPLOKq"
      },
      "outputs": [],
      "source": [
        "#Performing the train-test split. For the sake of testing the model, we used 80-20 split.\n",
        "X_train = input.iloc[:71450]\n",
        "X_test = input.iloc[71451:]\n",
        "Y_train = output.iloc[:71450]\n",
        "Y_test = output.iloc[71451:]\n",
        "# X_test = inputTest.iloc[:] #For running it on the actual test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4IGIP1ygWcR"
      },
      "outputs": [],
      "source": [
        "# X_train = X_train.iloc[:,7-8].fillna(' ')\n",
        "# X_test = X_test.iloc[:7-8].fillna(' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwrJWvheHEge"
      },
      "outputs": [],
      "source": [
        "X_test.iloc[:,-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4M9Rf1pzbyjG"
      },
      "source": [
        "## **Training the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOdc7JIVpHfw"
      },
      "outputs": [],
      "source": [
        "# import gensim\n",
        "# print(\"gensim version:\", gensim.__version__)\n",
        "\n",
        "# word2vec_path = \"/content/drive/MyDrive/ML_Project/GoogleNews-vectors-negative300.bin\"\n",
        "\n",
        "# # we only load 200k most common words from Google News corpus \n",
        "# word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_path, binary=True, limit=200000) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DVa6XUsuCtG"
      },
      "outputs": [],
      "source": [
        "# def get_average_vec(tokens_list, vector, generate_missing=False, k=300):\n",
        "#     \"\"\"\n",
        "#         Calculate average embedding value of sentence from each word vector\n",
        "#     \"\"\"\n",
        "#     # for word in tokens_list:\n",
        "#     #   print(word)\n",
        "#     if len(tokens_list)<1:\n",
        "#         return np.zeros(k)\n",
        "    \n",
        "#     if generate_missing:\n",
        "#         vectorized = [vector[word] if word in vector else np.random.rand(k) for word in tokens_list]\n",
        "#     else:\n",
        "#         vectorized = [vector[word] if word in vector else np.zeros(k) for word in tokens_list]\n",
        "    \n",
        "#     length = len(vectorized)\n",
        "#     summed = np.sum(vectorized, axis=0)\n",
        "#     averaged = np.divide(summed, length)\n",
        "#     return averaged\n",
        "\n",
        "# def get_embeddings(vectors, text, generate_missing=False, k=300):\n",
        "#     \"\"\"\n",
        "#         create the sentence embedding\n",
        "#     \"\"\"\n",
        "#     print(len(text))\n",
        "#     emdeddings = []\n",
        "#     # print(text[4])\n",
        "#     for i in range(len(text)):\n",
        "#       # text[i] = word_tokenize(text[i])\n",
        "#       emdeddings.append(get_average_vec(text[i], vectors, generate_missing=generate_missing, k=k))\n",
        "#     return emdeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYldUw9rxI1c"
      },
      "outputs": [],
      "source": [
        "# embeddings_word2vec = get_embeddings(word2vec_model, preprocessed_test_comments, k=300)\n",
        "# embeddings_word2vec_train = get_embeddings(word2vec_model, preprocessed_comments, k=300)\n",
        "# print(\"The sentence: \\\"%s\\\" got embedding values: \" % preprocessed_test_comments[0])\n",
        "# print(embeddings_word2vec[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P921cIzhU7AB"
      },
      "outputs": [],
      "source": [
        "new_features = list(X_train.columns[3:6])\n",
        "new_test_features = list(X_test.columns[3:6])\n",
        "new_features = csr_matrix(X_train[new_features].values.astype(float))\n",
        "# new_tf = csr_matrix[X_test[new_test_features].values]\n",
        "print(new_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94ZjVqwT807B"
      },
      "outputs": [],
      "source": [
        "wordVectorizer = TfidfVectorizer(sublinear_tf = True,strip_accents = 'unicode', min_df = 2, max_df = 0.5,max_features = 20000, lowercase = True, analyzer = \"word\", ngram_range=(1,2), \n",
        "                                 stop_words = \"english\", dtype=np.float32) #Takes words can returns a matrix representing the text in terms of the occurences and frequencies of the vocabulary of the whole dataset.\n",
        "charVectorizer = TfidfVectorizer(sublinear_tf = True,strip_accents = 'unicode', min_df = 2, max_df = 0.5, max_features = 10000, lowercase = True, analyzer = \"char\", ngram_range=(3,5), \n",
        "                                 stop_words = \"english\", dtype=np.float32)\n",
        "Vectorizer = make_union(wordVectorizer, charVectorizer, n_jobs=-1)\n",
        "X_train_TFrep = Vectorizer.fit_transform(X_train.iloc[:,-1]) #first fitting our estimator to the data to get a matrix representation->transforming count-matrix to tf-idf rep.\n",
        "X_test_TFrep= Vectorizer.transform(X_test.iloc[:, -1])\n",
        "X_test_TFrep.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAknw-xr3GNT"
      },
      "outputs": [],
      "source": [
        "X_test_TFrep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nnq0QN87KhZT"
      },
      "outputs": [],
      "source": [
        "# Vectorizer = TfidfVectorizer(max_features = 10000, lowercase = True, analyzer = \"char\", ngram_range=(3,7), stop_words = \"english\", dtype=np.float32) #Takes words can returns a matrix representing the text in terms of the occurences and frequencies of the vocabulary of the whole dataset.\n",
        "# X_train_2 = Vectorizer.fit_transform(X_train.iloc[:,7-8]) #first fitting our estimator to the data to get a matrix representation->transforming count-matrix to tf-idf rep.\n",
        "# X_test_2 = Vectorizer.transform(X_test.iloc[:, 7-8])\n",
        "# X_test_2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uIbaMjiKyp8"
      },
      "outputs": [],
      "source": [
        "# X_train_TFrep = hstack([X_train_word, X_train_2])\n",
        "# X_test_TFrep = hstack([X_test_word, X_test_2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9ZWOwcRBbAt"
      },
      "outputs": [],
      "source": [
        "# X_train_word[4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEeqGlPQsHAR"
      },
      "outputs": [],
      "source": [
        "def merge_features(text, data, engineered_features,frame, sparse = 0):\n",
        "  \n",
        "    new_features = csr_matrix(frame[engineered_features].values)\n",
        "    if np.isnan(new_features.data).any():\n",
        "        new_features.data = np.nan_to_num(new_features.data)\n",
        "    return hstack([text, new_features])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6Tv0kkguC4N"
      },
      "outputs": [],
      "source": [
        "# merge_features(X_train_TFrep, X_train, new_features, X_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = X_test.iloc[:, 1:2]\n",
        "df"
      ],
      "metadata": {
        "id": "cUywZsNKJPlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_gpblLtLvj4"
      },
      "source": [
        "## **Testing and evaluating the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMU7ksQo0EkP"
      },
      "outputs": [],
      "source": [
        "#OVR is a multiclass classifier. It creates a classifier for each column like for eg: [harsh, rest] and LR is used for each classifier to find the predicted probabilities.\n",
        "\n",
        "classifier = OneVsRestClassifier(LogisticRegression(solver = 'saga'))\n",
        "\n",
        "classifier.fit(X_train_TFrep, Y_train)\n",
        "probability = classifier.predict_proba(X_test_TFrep)\n",
        "prediction = classifier.predict(X_test_TFrep)\n",
        "\n",
        "# classifier.fit(merge_features(X_train_TFrep, X_train, new_features, X_train), Y_train)\n",
        "# probability = classifier.predict_proba(merge_features(X_test_TFrep, X_test, new_features, X_test))\n",
        "# prediction = classifier.predict(merge_features(X_test_TFrep, X_test, new_features, X_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction.shape\n",
        "df = X_test.iloc[:, 1:2]\n",
        "df2 = pd.DataFrame(probability)\n",
        "df = pd.concat([df, df2], axis=1, ignore_index=True)\n",
        "df.to_csv(\"2tfidf.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "NoZwLTFiJXQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnojMG01SEUk"
      },
      "outputs": [],
      "source": [
        "print('Test accuracy is {}'.format(roc_auc_score(Y_test, prediction)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GclV4v7W23kk"
      },
      "outputs": [],
      "source": [
        "!cp 2tfidf5.csv /content/drive/MyDrive/ML_Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dROZ_Rm2fN33"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=50, criterion= \"entropy\", random_state = 0)\n",
        "\n",
        "model.fit(X_train_TFrep, Y_train)\n",
        "# model.fit(merge_features(X_train_TFrep, X_train, new_features, X_train), Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7h3q825gvEd"
      },
      "outputs": [],
      "source": [
        "prediction = model.predict(X_test_TFrep)\n",
        "# prediction = model.predict(merge_features(X_test_TFrep, X_test, new_features, X_test))\n",
        "print(\"Accuracy score is: \" + str(roc_auc_score(Y_test, prediction)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uxrc4QGlYwi"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "# from sklearn.preprocessing.MultiLabelBinarizer import MultiLabelBinarizer\n",
        "clf = OneVsRestClassifier(XGBClassifier())\n",
        "\n",
        "clf.fit(X_train_TFrep, Y_train)\n",
        "# clf.fit(merge_features(X_train_TFrep, X_train, new_features, X_train), Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3rT6ctKm-cz"
      },
      "outputs": [],
      "source": [
        "prediction = clf.predict(X_test_TFrep)\n",
        "# prediction = clf.predict(merge_features(X_test_TFrep, X_test, new_features, X_test))\n",
        "print(\"Accuracy score is: \" + str(roc_auc_score(Y_test, prediction)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5WggxN748co"
      },
      "outputs": [],
      "source": [
        "# #OVR is a multiclass classifier. It creates a classifier for each column like for eg: [harsh, rest] and LR is used for each classifier to find the predicted probabilities.\n",
        "# classifier = OneVsRestClassifier(LogisticRegression(solver = 'saga'))\n",
        "# categories = [\"harsh\", \"extremely_harsh\", \"vulgar\", \"disrespect\", \"threatening\", \"targeted_hate\"]\n",
        "# classifier.fit(embeddings_word2vec_train, Y_train)\n",
        "# probability = classifier.predict_proba(embeddings_word2vec)\n",
        "# probability = np.round_(probability, decimals = 2)\n",
        "# prediction = classifier.predict(embeddings_word2vec)\n",
        "# print('Test accuracy is {}'.format(roc_auc_score(Y_test, prediction)))\n",
        "# #After fitting and predicting the data, we dump the outputs into a .csv\n",
        "# # print(probability)\n",
        "# prediction.shape\n",
        "# df = pd.DataFrame()\n",
        "# df = X_test.iloc[:, 0:1]\n",
        "# df2 = pd.DataFrame(probability)\n",
        "# df = pd.concat([df, df2], axis=1, ignore_index=True)\n",
        "# # df.info()\n",
        "# df.to_csv(\"data1.csv\")\n",
        "# df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7eBpO93-mF9"
      },
      "source": [
        "We have implemented the same OVR classifier but with multinomial NB to predict the probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSLxHDcS_qkw"
      },
      "outputs": [],
      "source": [
        "# classifier2 = OneVsRestClassifier(MultinomialNB(fit_prior = True, class_prior = None))\n",
        "# categories = [\"harsh\", \"extremely_harsh\", \"vulgar\", \"disrespect\", \"threatening\", \"targeted_hate\"]\n",
        "\n",
        "# classifier2.fit(merge_features(X_train_TFrep, X_train, new_features, X_train), Y_train)\n",
        "# # compute the testing accuracy\n",
        "# prediction = classifier2.predict(merge_features(X_test_TFrep, X_test, new_features, X_test))\n",
        "# print('Test accuracy is {}'.format(roc_auc_score(Y_test, prediction)))\n",
        "# print(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSlPbmyc-2yf"
      },
      "source": [
        "An ensemble of both the models implemented above.\n",
        "\n",
        "Done to combine the predictions of multiple base estimators/models which are LR and MNB here to improve overall accuracies and give best result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3RA2GR64sYB"
      },
      "outputs": [],
      "source": [
        "from sklearn.multioutput import ClassifierChain\n",
        "\n",
        "base_lr = LogisticRegression(solver = \"saga\")\n",
        "chain = ClassifierChain(base_lr, order='random', random_state=0)\n",
        "chain.fit(X_train_TFrep, Y_train)\n",
        "probability = chain.predict_proba(X_test_TFrep)\n",
        "prediction = chain.predict(X_test_TFrep)\n",
        "\n",
        "# chain.fit(merge_features(X_train_TFrep, X_train, new_features, X_train), Y_train)\n",
        "# prediction = chain.predict(merge_features(X_test_TFrep, X_test, new_features, X_test))\n",
        "# probability = np.round_(probability, decimals = 2)\n",
        "\n",
        "# print('Test accuracy is {}'.format(roc_auc_score(Y_test, prediction)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ix0EcytMTwPm"
      },
      "outputs": [],
      "source": [
        "ensemble = VotingClassifier(estimators =[('lr', classifier), ('chain', chain)],voting='soft')\n",
        "categories = [\"harsh\", \"extremely_harsh\", \"vulgar\", \"disrespect\", \"threatening\", \"targeted_hate\"]\n",
        "for category in categories:\n",
        "  ensemble.fit(X_train_TFrep, Y_train[category])\n",
        "  a = ensemble.predict_proba(X_test_TFrep)\n",
        "  prediction = ensemble.predict(X_test_TFrep)\n",
        "  print(\"for category: \" + category + \" \" + str(roc_auc_score(Y_test[category], prediction)))\n",
        "# print(\"acc score: \" + str(roc_auc_score(Y_test, prediction)))\n",
        "#create our voting classifier, inputting our models\n",
        "# ensemble = VotingClassifier(estimators, voting=’hard’)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2W-iLaAX50Je"
      },
      "outputs": [],
      "source": [
        "# from sklearn.multioutput import ClassifierChain\n",
        "# base_lr = LogisticRegression(solver = \"saga\")\n",
        "# chain = ClassifierChain(base_lr, order='random', random_state=0)\n",
        "# # chain.fit(embeddings_word2vec_train, Y_train)\n",
        "# chain.fit(merge_features(embeddings_word2vec_train, X_train, new_features, X_train), Y_train)\n",
        "# prediction = chain.predict(merge_features(embeddings_word2vec, X_test, new_features, X_test))\n",
        "# # probability = chain.predict_proba(embeddings_word2vec)\n",
        "# # probability = np.round_(probability, decimals = 2)\n",
        "# # prediction = chain.predict(embeddings_word2vec)\n",
        "# print('Test accuracy is {}'.format(roc_auc_score(Y_test, prediction)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}